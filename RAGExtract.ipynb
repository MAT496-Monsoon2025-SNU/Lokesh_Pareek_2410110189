{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca94ed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq  # using Groq LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ca3f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API keys from .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b768767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Change webpage here\n",
    "URL = \"https://maths.du.ac.in/faculty-profile/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c248a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Fetching webpage: {URL}\")\n",
    "response = requests.get(URL)\n",
    "soup = BeautifulSoup(response.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3f0a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get text chunks (faculty profile section)\n",
    "full_doc = soup.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3794956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Extract relevant blocks (heuristic: each faculty entry has an email)\n",
    "email_pattern = r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\"\n",
    "blocks = []\n",
    "for block in full_doc.split(\"\\n\"):\n",
    "    if re.search(email_pattern, block):\n",
    "        blocks.append(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fdbbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Initialize LLM (Groq example, can swap with OpenAI if needed)\n",
    "model = ChatGroq(model=\"llama-3.1-8b-instant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec45072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Ask LLM to structure the data\n",
    "prompt = f\"\"\"\n",
    "You are given raw text blocks extracted from a faculty webpage:\n",
    "\n",
    "{blocks}\n",
    "\n",
    "Task: Extract the following fields in clean structured format:\n",
    "- Name\n",
    "- Position/Designation\n",
    "- Office number (if available)\n",
    "- Email\n",
    "\n",
    "Output as a neat table (markdown format).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f2f5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e573ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== LLM Organized Faculty Info ===\\n\")\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
